ğŸ“„ Document Intelligence

Minimal PDF Question Answering System

Document Intelligence is a clean, local-first PDF question answering system that allows users to upload documents, index their contents, and ask natural language questions to retrieve accurate, source-backed answers.

Built using LlamaIndex, HuggingFace open-source models, and Streamlit, the project emphasizes clarity, simplicity, and performance, paired with a minimal black-and-white editorial UI.

ğŸ” Core Topics Covered

Document Intelligence

Retrieval-Augmented Generation (RAG)

PDF Parsing & Text Extraction

Vector Embeddings & Semantic Search

LLM-powered Question Answering

Minimal UI/UX Design for AI Applications

Local-first AI Systems (No Paid APIs)

âœ¨ Key Features

ğŸ“‚ Upload multiple PDF documents

ğŸ§  Semantic indexing using vector embeddings

ğŸ” Ask natural language questions across documents

ğŸ“„ Page-level context retrieval

âš¡ Fast local inference (no external API dependency)

ğŸ¨ Minimal black & white editorial UI

ğŸ›¡ï¸ Fully offline-capable after setup

ğŸ§± Architecture Overview
User
 â†“
Streamlit UI
 â†“
Query Engine (LlamaIndex)
 â†“
Vector Store (Local)
 â†“
PDF Content + Metadata

ğŸ› ï¸ Tech Stack
Frontend

Streamlit

Custom CSS (Minimal Black & White UI)

Backend

Python 3.10+

LlamaIndex

HuggingFace Transformers

Sentence Transformers (Embeddings)

Storage

Local Vector Store (LlamaIndex SimpleVectorStore)

Persistent Index Storage

Document Processing

PyPDF / PDF Reader utilities

ğŸ“ Project Structure
document-intelligence/
â”‚
â”œâ”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ ingest.py             # PDF loading & indexing
â”œâ”€â”€ query.py              # Query engine logic
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/          # Uploaded PDFs
â”‚   â””â”€â”€ storage/          # Persisted index
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ“– How It Works

Upload one or more PDF documents

The system extracts and chunks text

Embeddings are generated and stored locally

A semantic index is built and persisted

User questions are matched against relevant chunks

The LLM generates an answer using retrieved context

ğŸ§  Example Questions

â€œExplain data mining concepts discussed in page 1.â€

â€œWhat are the advantages of clustering algorithms?â€

â€œSummarize the introduction section.â€

ğŸ¨ UI Philosophy

Black & white only

No visual noise

Typography-focused layout

Content-first interaction

Editorial / studio-inspired aesthetic

The interface is designed to disappear â€” letting documents speak.

ğŸ” Privacy & Cost

âŒ No OpenAI / paid APIs

âœ… Runs fully on local machine

âœ… Documents never leave your system

ğŸ“Œ Use Cases

Study notes & textbooks

Research papers

Exam preparation

Technical documentation

Personal knowledge bases
